{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amruthayenikonda/simple-web-scraping-using-pandas?scriptVersionId=149172278\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"#  Simple Web Scraping using Pandas","metadata":{}},{"cell_type":"markdown","source":"**In this notebook, we'll be scraping data from wikipedia page using Pandas library in Python.**","metadata":{}},{"cell_type":"markdown","source":"Before scraping any website make sure to check if scraping is allowed by the website to avoid scraping illegally.","metadata":{}},{"cell_type":"code","source":"import requests\n\ndef is_url_scrapable(url):\n    try:\n        robots_txt_url = f\"{url.rstrip('/')}/robots.txt\"\n        response = requests.get(robots_txt_url)\n# to check if the response status code is 200 (OK)\n        if response.status_code == 200:\n            robots_txt = response.text\n            if \"User-agent: *\" in robots_txt:\n                return \"Disallow:\" not in robots_txt\n            else:\n                return True\n        else:\n            return True\n    except Exception as e:\n        print(f\"Error checking scraping permissions: {str(e)}\")\n        return False\n\nurl_to_check = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours_by_women\"\nis_allowed = is_url_scrapable(url_to_check)\nprint(f\"Is scraping allowed for {url_to_check}? {is_allowed}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T13:18:25.142Z","iopub.execute_input":"2023-11-03T13:18:25.142392Z","iopub.status.idle":"2023-11-03T13:18:25.716299Z","shell.execute_reply.started":"2023-11-03T13:18:25.142351Z","shell.execute_reply":"2023-11-03T13:18:25.714154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-11-03T13:18:54.624477Z","iopub.execute_input":"2023-11-03T13:18:54.624873Z","iopub.status.idle":"2023-11-03T13:18:54.940097Z","shell.execute_reply.started":"2023-11-03T13:18:54.624842Z","shell.execute_reply":"2023-11-03T13:18:54.93903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tables = pd.read_html('https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours_by_women')#this will fetch in tables present in the page.","metadata":{"execution":{"iopub.status.busy":"2023-11-03T13:19:13.082574Z","iopub.execute_input":"2023-11-03T13:19:13.083075Z","iopub.status.idle":"2023-11-03T13:19:13.522876Z","shell.execute_reply.started":"2023-11-03T13:19:13.083044Z","shell.execute_reply":"2023-11-03T13:19:13.521846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tables)#to check how many tables are in there in the page and make sure to go through the page once to decide on which table you want to scrape.","metadata":{"execution":{"iopub.status.busy":"2023-11-03T13:20:41.338086Z","iopub.execute_input":"2023-11-03T13:20:41.338452Z","iopub.status.idle":"2023-11-03T13:20:41.347256Z","shell.execute_reply.started":"2023-11-03T13:20:41.338424Z","shell.execute_reply":"2023-11-03T13:20:41.346196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tables[1]#so i want to scrape the second table by indexing","metadata":{"execution":{"iopub.status.busy":"2023-11-03T13:21:12.634525Z","iopub.execute_input":"2023-11-03T13:21:12.634896Z","iopub.status.idle":"2023-11-03T13:21:12.663228Z","shell.execute_reply.started":"2023-11-03T13:21:12.634866Z","shell.execute_reply":"2023-11-03T13:21:12.662042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert scraped data to csv file\ntables[1].to_csv('data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T13:22:41.333345Z","iopub.execute_input":"2023-11-03T13:22:41.333738Z","iopub.status.idle":"2023-11-03T13:22:41.342188Z","shell.execute_reply.started":"2023-11-03T13:22:41.333708Z","shell.execute_reply":"2023-11-03T13:22:41.34078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('data.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-03T13:22:49.944613Z","iopub.execute_input":"2023-11-03T13:22:49.944911Z","iopub.status.idle":"2023-11-03T13:22:49.967551Z","shell.execute_reply.started":"2023-11-03T13:22:49.944886Z","shell.execute_reply":"2023-11-03T13:22:49.966429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: If you are willing to run your code in Google Colab, you can use the below code to download the CSV file into your PC.","metadata":{}},{"cell_type":"code","source":"#download csv file from colab\nfrom google.colab import files\nfiles.download('data.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, this is a simple way to web scrape data using Pandas.Using the CSV file you can later perform data cleaning and Vizualisations.","metadata":{}},{"cell_type":"markdown","source":"# **Thank you!**","metadata":{}}]}